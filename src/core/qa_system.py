import os
import warnings
import json
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Any
from datetime import datetime
import uuid
import time
import sys

from rouge_score import rouge_scorer
from nltk.translate.bleu_score import sentence_bleu
import evaluate
from bert_score import score as bert_score

from config import TransneftConfig, EvaluationCriteria 
from benchmark_utils import BenchmarkAnalyzer, export_benchmark_report
from database_models import DatabaseManager, ChatMessage, EvaluationResult, db_manager
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction  

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
current_dir = os.path.dirname(os.path.abspath(__file__))
src_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, src_root)

from utils.config import VECTOR_STORE_DIR, TOP_K_RESULTS, SIMILARITY_THRESHOLD
from core.vector_store import VectorStore
from core.retrieval_engine import RetrievalEngine


class TransneftQASystem:
    """–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è QA —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ü–ê–û ¬´–¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å¬ª"""

    def __init__(self, vector_store_path: str = VECTOR_STORE_DIR):
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è QA —Å–∏—Å—Ç–µ–º—ã –ü–ê–û ¬´–¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å¬ª...")
        self.vector_store = VectorStore()
        self.retrieval_engine = RetrievalEngine()
        self.vector_store_path = vector_store_path
        self.initialized = False
        self.processing_time = None
        self.db_manager = db_manager  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π db_manager

        try:
            self.vector_store.load_index(vector_store_path)
            self.initialized = True
            print("‚úÖ QA —Å–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = self.vector_store.get_stats()
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã: {stats['total_chunks']} chunks, {stats['total_vectors']} –≤–µ–∫—Ç–æ—Ä–æ–≤")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ QA —Å–∏—Å—Ç–µ–º—ã: {e}")
            print("\nüí° –†–µ—à–µ–Ω–∏–µ: –ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É —Å–∏—Å—Ç–µ–º—ã:")
            print("   python scripts/setup_system.py")
            raise

    def answer_question(self, question: str, session_id: str = "default", user_id: str = "user") -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        if not self.initialized:
            return {
                "result": "–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É —Å–∏—Å—Ç–µ–º—ã.",
                "source_documents": [],
                "confidence": 0.0
            }

        if not question or not question.strip():
            return {
                "result": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –ü–ê–û ¬´–¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å¬ª.",
                "source_documents": [],
                "confidence": 0.0
            }

        start_time = time.time()

        try:
            # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
            search_results = self.vector_store.search(
                question,
                k=TOP_K_RESULTS,
                threshold=SIMILARITY_THRESHOLD
            )

            if not search_results:
                return {
                    "result": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ü–ê–û ¬´–¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å¬ª –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.",
                    "source_documents": [],
                    "confidence": 0.0
                }

            # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
            contexts = [chunk for chunk, metadata, score in search_results]
            source_documents = [
                {
                    "content": chunk,
                    "metadata": metadata,
                    "score": float(score)
                }
                for chunk, metadata, score in search_results
            ]

            # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            answer = self.retrieval_engine.answer_question(question, contexts)

            self.processing_time = time.time() - start_time
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            message_id = -1
            try:
                chat_message = ChatMessage(
                    session_id=session_id,
                    user_id=user_id,
                    question=question,
                    answer=answer,
                    sources=json.dumps(source_documents, ensure_ascii=False),
                    timestamp=datetime.now(),
                    response_time=self.processing_time,
                    model_used="transneft_qa_system"
                )
                message_id = self.db_manager.save_chat_message(chat_message)
            except Exception as db_error:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {db_error}")

            return {
                "result": answer,
                "source_documents": source_documents,
                "confidence": float(search_results[0][2]) if search_results else 0.8,
                "message_id": message_id,
                "processing_time": self.processing_time
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {e}")
            return {
                "result": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}",
                "source_documents": [],
                "confidence": 0.0,
                "error": str(e)
            }

    def get_search_stats(self, question: str) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–∏—Å–∫–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        if not self.initialized:
            return {"error": "–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"}

        try:
            search_results = self.vector_store.search(question, k=TOP_K_RESULTS)

            return {
                'question': question,
                'question_type': self.retrieval_engine.analyze_question_type(question) if hasattr(self.retrieval_engine, 'analyze_question_type') else "unknown",
                'results_found': len(search_results),
                'top_scores': [float(score) for _, _, score in search_results],
                'top_sections': [metadata.get('sections', ['Unknown'])[0] if metadata.get('sections') else 'Unknown' for _, metadata, _ in search_results],
                'processing_time': self.processing_time,
            }
        except Exception as e:
            return {"error": str(e)}

    def get_system_info(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ"""
        if not self.initialized:
            return {"status": "–ù–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"}

        stats = self.vector_store.get_stats()

        return {
            "status": "–ê–∫—Ç–∏–≤–Ω–∞",
            "vector_store": stats,
            "retrieval_engine": "Retrieval-only (–±–µ–∑ LLM)",
            "model": stats.get("model", "Unknown"),
            "total_chunks": stats.get("total_chunks", 0),
            "similarity_threshold": SIMILARITY_THRESHOLD
        }
        
    def load_chat_history(self, session_id: str) -> List[Tuple[str, str, list, str]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ –∏–∑ –ë–î"""
        try:
            messages = self.db_manager.get_chat_history(session_id)
            chat_history = []
            for msg in messages:
                try:
                    sources = json.loads(msg['sources']) if msg['sources'] else []
                except:
                    sources = []

                try:
                    timestamp_str = msg['timestamp'].strftime("%H:%M:%S") if hasattr(msg['timestamp'], 'strftime') else str(msg['timestamp'])
                except:
                    timestamp_str = ""

                chat_history.append((
                    msg['question'] if msg['question'] else "",
                    msg['answer'] if msg['answer'] else "",
                    sources,
                    timestamp_str
                ))
            return chat_history
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
            return []

    def test_connection(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã"""
        if not self.initialized:
            return False

        try:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            test_results = self.vector_store.search("–¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å", k=1)
            return len(test_results) > 0
        except:
            return False


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ QA —Å–∏—Å—Ç–µ–º—ã
    try:
        qa_system = TransneftQASystem()

        test_questions = [
            "–°–∫–æ–ª—å–∫–æ –∞–∫—Ü–∏–π –≤ —É—Å—Ç–∞–≤–Ω–æ–º –∫–∞–ø–∏—Ç–∞–ª–µ?",
            "–ö–æ–≥–¥–∞ –±—ã–ª–∞ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∫–æ–º–ø–∞–Ω–∏—è?",
            "–ö–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏?",
            "–ö—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –∞—É–¥–∏—Ç–æ—Ä–æ–º –∫–æ–º–ø–∞–Ω–∏–∏?"
        ]

        print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï QA –°–ò–°–¢–ï–ú–´:")
        print("=" * 50)

        for i, question in enumerate(test_questions, 1):
            print(f"\n{i}. ‚ùì –í–æ–ø—Ä–æ—Å: {question}")
            result = qa_system.answer_question(question, "test_session")
            print(f"   üí° –û—Ç–≤–µ—Ç: {result['result']}")
            print(f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.3f}")
            print(f"   üìÑ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {len(result['source_documents'])}")

        print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")