import os
import sys
import docx
import re
import json
from typing import List, Dict

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
current_dir = os.path.dirname(os.path.abspath(__file__))
src_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, src_root)

from utils.config import SECTION_HEADERS, ELEMENTS_PATH


class DocumentParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ .docx –¥–ª—è –ü–ê–û ¬´–¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å¬ª"""

    def __init__(self):
        self.section_headers = SECTION_HEADERS

    def parse_document(self, doc_path: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏—Ç .docx –¥–æ–∫—É–º–µ–Ω—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã"""
        print("üìÑ –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")

        try:
            if not os.path.exists(doc_path):
                raise FileNotFoundError(f"–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {doc_path}")

            doc = docx.Document(doc_path)
            elements = []
            current_section = "–û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
            element_id = 0

            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                if not text:
                    continue

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞
                element_type = self._classify_element(text, paragraph.style.name)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–¥–µ–ª –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                if element_type == "section_header":
                    current_section = text

                # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç
                element = {
                    'element_id': element_id,
                    'type': element_type,
                    'text': text,
                    'section': current_section,
                    'style': paragraph.style.name,
                    'word_count': len(text.split())
                }

                elements.append(element)
                element_id += 1

            print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: {len(elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã
            self._save_elements(elements)

            return elements

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return []

    def _classify_element(self, text: str, style: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤
        if any(header.lower() in text.lower() for header in self.section_headers):
            return "section_header"

        # –°—Ç–∏–ª–µ–≤—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        if style and 'heading' in style.lower():
            return "section_header"

        # –ì–æ–¥—ã (1990, 2000 –∏ —Ç.–¥.)
        if re.match(r'^\d{3,4}\.?$', text.strip()):
            return "year_header"

        # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        if re.match(r'^\d+[\.\)]', text.strip()):
            return "numbered_item"

        # –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        if text.strip().startswith(('-', '‚Ä¢', '‚Äî')):
            return "bullet_item"

        # –ü—Ä–æ–µ–∫—Ç—ã
        if re.search(r'[–ü–ø]—Ä–æ–µ–∫—Ç|[–°—Å]—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ', text) and len(text) < 150:
            return "project_header"

        # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        return "paragraph"

    def _save_elements(self, elements: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —Ñ–∞–π–ª"""
        try:
            with open(ELEMENTS_PATH, 'w', encoding='utf-8') as f:
                json.dump(elements, f, ensure_ascii=False, indent=2)
            print(f"üíæ –≠–ª–µ–º–µ–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {ELEMENTS_PATH}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {e}")

    def analyze_document(self, elements: List[Dict]):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        print("\nüìä –ê–ù–ê–õ–ò–ó –î–û–ö–£–ú–ï–ù–¢–ê:")
        print("-" * 40)

        total_elements = len(elements)
        sections = set()
        element_types = {}

        for elem in elements:
            sections.add(elem['section'])
            elem_type = elem['type']
            element_types[elem_type] = element_types.get(elem_type, 0) + 1

        print(f"üìà –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {total_elements}")
        print(f"üìÇ –†–∞–∑–¥–µ–ª–æ–≤: {len(sections)}")
        print("üîß –¢–∏–ø—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤:")
        for elem_type, count in element_types.items():
            percentage = (count / total_elements) * 100
            print(f"   - {elem_type}: {count} ({percentage:.1f}%)")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã
        print("\nüìë –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã:")
        for i, section in enumerate(list(sections)[:10]):
            print(f"   {i + 1}. {section}")


if __name__ == "__main__":
    from utils.config import DOCUMENT_PATH

    parser = DocumentParser()
    elements = parser.parse_document(DOCUMENT_PATH)
    if elements:
        parser.analyze_document(elements)