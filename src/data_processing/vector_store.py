# scripts/vector_store.py
import json
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import torch
import os
from typing import List, Dict, Tuple


class VectorStore:
    def __init__(self, model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.model = SentenceTransformer(model_name, device=self.device)
        self.index = None
        self.chunks = []
        self.chunk_metadata = []

    def create_embeddings(self, chunks: List[Dict]) -> None:
        """–°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö chunks"""
        print("–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")

        self.chunks = [chunk['text'] for chunk in chunks]
        self.chunk_metadata = [chunk['metadata'] for chunk in chunks]

        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        embeddings = self.model.encode(
            self.chunks,
            batch_size=8,
            show_progress_bar=True,
            convert_to_tensor=True
        )

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –¥–ª—è FAISS
        embeddings_np = embeddings.cpu().numpy() if self.device == "cuda" else embeddings.numpy()

        # –°–æ–∑–¥–∞–µ–º FAISS –∏–Ω–¥–µ–∫—Å
        dimension = embeddings_np.shape[1]
        self.index = faiss.IndexFlatIP(dimension)  # Inner Product –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
        faiss.normalize_L2(embeddings_np)
        self.index.add(embeddings_np)

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å —Å {self.index.ntotal} –≤–µ–∫—Ç–æ—Ä–∞–º–∏")

    def search(self, query: str, k: int = 5) -> List[Tuple[str, Dict, float]]:
        """–ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö chunks"""
        if self.index is None:
            raise ValueError("–ò–Ω–¥–µ–∫—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ create_embeddings()")

        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.model.encode([query], convert_to_tensor=True)
        query_embedding_np = query_embedding.cpu().numpy() if self.device == "cuda" else query_embedding.numpy()

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
        faiss.normalize_L2(query_embedding_np)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        scores, indices = self.index.search(query_embedding_np, k)

        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx < len(self.chunks):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
                results.append((
                    self.chunks[idx],
                    self.chunk_metadata[idx],
                    float(score)
                ))

        return results

    def save_index(self, save_path: str = "models/vector_store"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ"""
        os.makedirs(save_path, exist_ok=True)

        faiss.write_index(self.index, f"{save_path}/faiss.index")

        with open(f"{save_path}/chunks.json", "w", encoding="utf-8") as f:
            json.dump(self.chunks, f, ensure_ascii=False, indent=2)

        with open(f"{save_path}/metadata.json", "w", encoding="utf-8") as f:
            json.dump(self.chunk_metadata, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {save_path}")

    def load_index(self, load_path: str = "models/vector_store"):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ"""
        self.index = faiss.read_index(f"{load_path}/faiss.index")

        with open(f"{load_path}/chunks.json", "r", encoding="utf-8") as f:
            self.chunks = json.load(f)

        with open(f"{load_path}/metadata.json", "r", encoding="utf-8") as f:
            self.chunk_metadata = json.load(f)

        print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ {load_path}")


# –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
if __name__ == "__main__":
    # –ó–∞–≥—Ä—É–∂–∞–µ–º chunks
    with open("data/processed/document_chunks.json", "r", encoding="utf-8") as f:
        chunks = json.load(f)

    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(chunks)} chunks –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞")

    # –°–æ–∑–¥–∞–µ–º –∏ –Ω–∞–ø–æ–ª–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    vector_store = VectorStore()
    vector_store.create_embeddings(chunks)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å
    vector_store.save_index()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    test_queries = [
        "–ö–æ–≥–¥–∞ –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å?",
        "–ö–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã —É –∫–æ–º–ø–∞–Ω–∏–∏?",
        "–°–∫–æ–ª—å–∫–æ –∫–∏–ª–æ–º–µ—Ç—Ä–æ–≤ —Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥–æ–≤?",
        "–ö—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –∞—É–¥–∏—Ç–æ—Ä–æ–º –∫–æ–º–ø–∞–Ω–∏–∏?"
    ]

    print("\nüîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–û–ò–°–ö–ê:")
    for query in test_queries:
        print(f"\n–ó–∞–ø—Ä–æ—Å: '{query}'")
        results = vector_store.search(query, k=3)

        for i, (chunk, metadata, score) in enumerate(results):
            print(f"  {i + 1}. [Score: {score:.3f}] {chunk[:100]}...")