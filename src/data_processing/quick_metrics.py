# scripts/quick_metrics.py
import json
import numpy as np
from simple_rag_system import SimpleRAGSystem


def calculate_basic_metrics():
    """–ë—ã—Å—Ç—Ä—ã–π —Ä–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫"""

    rag_system = SimpleRAGSystem()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º QA –±–µ–Ω—á–º–∞—Ä–∫
    with open("data/processed/qa_benchmark_final.json", "r", encoding="utf-8") as f:
        qa_benchmark = json.load(f)

    results = []

    for i, qa_pair in enumerate(qa_benchmark[:20]):  # –¢–æ–ª—å–∫–æ 20 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        question = qa_pair['question']
        expected_chunk = qa_pair['chunk_id']

        result = rag_system.answer_question(question)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞–π–¥–µ–Ω –ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π chunk
        correct_chunk_found = any(
            source.get('chunk_id') == expected_chunk
            for source in result['sources']
        )

        results.append({
            'question': question,
            'confidence': result['confidence'],
            'correct_chunk_found': correct_chunk_found,
            'sources_count': len(result['sources'])
        })

    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    avg_confidence = np.mean([r['confidence'] for r in results])
    accuracy = np.mean([r['correct_chunk_found'] for r in results])

    metrics = {
        "retrieval_accuracy": accuracy,
        "average_confidence": avg_confidence,
        "evaluated_questions": len(results)
    }

    print("üìä –ë–ê–ó–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –°–ò–°–¢–ï–ú–´:")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞: {accuracy:.3f}")
    print(f"–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.3f}")
    print(f"–û—Ü–µ–Ω–µ–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(results)}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    with open("data/processed/basic_metrics.json", "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=2)

    return metrics


if __name__ == "__main__":
    calculate_basic_metrics()