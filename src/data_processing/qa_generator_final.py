# scripts/qa_generator_final.py
import json
import re
from typing import List, Dict


def create_final_qa_pairs(chunks: List[Dict]) -> List[Dict]:
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ QA –ø–∞—Ä—ã"""
    qa_pairs = []

    question_templates = {
        'company_info': [
            "–ö–æ–≥–¥–∞ –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –∫–æ–º–ø–∞–Ω–∏—è {company}?",
            "–ö–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ {company}?",
            "–ö–∞–∫–æ–π —É—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª {company}?",
            "–ö—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–º {company}?",
            "–ì–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≥–æ–ª–æ–≤–Ω–æ–π –æ—Ñ–∏—Å {company}?"
        ],
        'projects': [
            "–ß—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø—Ä–æ–µ–∫—Ç {project}?",
            "–ö–∞–∫–∏–µ —Ü–µ–ª–∏ —É –ø—Ä–æ–µ–∫—Ç–∞ {project}?",
            "–ö–æ–≥–¥–∞ –±—ã–ª —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø—Ä–æ–µ–∫—Ç {project}?",
            "–ö–∞–∫–∞—è –ø—Ä–æ—Ç—è–∂–µ–Ω–Ω–æ—Å—Ç—å {project}?",
            "–ö–∞–∫–∞—è –ø—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å {project}?"
        ],
        'facts': [
            "–°–∫–æ–ª—å–∫–æ {entity} —É –∫–æ–º–ø–∞–Ω–∏–∏?",
            "–ö–∞–∫–æ–≤–∞ {metric} –∫–æ–º–ø–∞–Ω–∏–∏?",
            "–ö—Ç–æ —è–≤–ª—è–µ—Ç—Å—è {role} –∫–æ–º–ø–∞–Ω–∏–∏?",
            "–ö–æ–≥–¥–∞ {event} –ø—Ä–æ–∏–∑–æ—à–ª–æ?",
            "–ì–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è {location}?"
        ]
    }

    for chunk in chunks:
        context = chunk['text']
        chunk_id = chunk['metadata']['chunk_id']
        sections = chunk['metadata']['sections']

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_type = classify_content(context, sections)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã
        questions = generate_typed_questions(context, content_type, question_templates)

        for question in questions:
            qa_pair = {
                "context": context,
                "question": question,
                "answer": "[–¢—Ä–µ–±—É–µ—Ç—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞]",
                "chunk_id": chunk_id,
                "sections": sections,
                "content_type": content_type,
                "metadata": chunk['metadata']
            }
            qa_pairs.append(qa_pair)

    return qa_pairs


def classify_content(text: str, sections: List[str]) -> str:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    text_lower = text.lower()
    sections_lower = [s.lower() for s in sections]

    if any(keyword in text_lower for keyword in ['–ø—Ä–æ–µ–∫—Ç', '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '—Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥', '–º–∞–≥–∏—Å—Ç—Ä–∞–ª—å']):
        return 'projects'
    elif any(keyword in text_lower for keyword in ['–æ—Å–Ω–æ–≤–∞–Ω', '—É—á—Ä–µ–∂–¥–µ–Ω', '—Å–æ–∑–¥–∞–Ω', '–¥–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏']):
        return 'company_info'
    elif any(keyword in text_lower for keyword in ['–∞–∫—Ü–∏', '–∫–∞–ø–∏—Ç–∞–ª', '–∞–∫—Ü–∏–æ–Ω–µ—Ä', '—Ä–µ–µ—Å—Ç—Ä']):
        return 'company_info'
    elif any(keyword in sections_lower for keyword in ['—Ñ–∞–∫—Ç—ã', '–∏—Å—Ç–æ—Ä–∏—è', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è']):
        return 'facts'
    else:
        return 'facts'


def generate_typed_questions(text: str, content_type: str, templates: Dict) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–∏–ø—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    questions = []

    if content_type == 'company_info':
        # –í–æ–ø—Ä–æ—Å—ã –æ –∫–æ–º–ø–∞–Ω–∏–∏
        company_variants = ["–¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å", "–∫–æ–º–ø–∞–Ω–∏–∏ –¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å", "–ü–ê–û –¢—Ä–∞–Ω—Å–Ω–µ—Ñ—Ç—å"]
        for template in templates['company_info']:
            for company in company_variants:
                questions.append(template.format(company=company))

    elif content_type == 'projects':
        # –í–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–µ–∫—Ç–∞—Ö
        projects = extract_projects(text)
        for project in projects[:2]:  # –ú–∞–∫—Å–∏–º—É–º 2 –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ chunk
            for template in templates['projects'][:2]:
                questions.append(template.format(project=project))

    else:  # facts
        # –§–∞–∫—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã
        entities = extract_entities(text)
        for entity in entities[:2]:
            for template in templates['facts'][:2]:
                if '{entity}' in template:
                    questions.append(template.format(entity=entity))
                elif '{metric}' in template:
                    questions.append(template.format(metric=entity))
                elif '{role}' in template:
                    questions.append(template.format(role=entity))
                elif '{event}' in template:
                    questions.append(template.format(event=entity))
                elif '{location}' in template:
                    questions.append(template.format(location=entity))

    return list(set(questions))[:3]  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 3 –≤–æ–ø—Ä–æ—Å–∞–º–∏


def extract_projects(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤"""
    projects = []

    # –ò—â–µ–º –ø—Ä–æ–µ–∫—Ç—ã –≤ –∫–∞–≤—ã—á–∫–∞—Ö
    quoted_projects = re.findall(r'[¬´"]([^¬ª"]+?)[¬ª"]', text)
    projects.extend(quoted_projects)

    # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤
    project_keywords = re.findall(r'(–ø—Ä–æ–µ–∫—Ç\s+[¬´"][^¬ª"]+[¬ª"]|–ø—Ä–æ–µ–∫—Ç\s+[–ê-–Ø][^.!?]{0,50})', text)
    projects.extend([p.strip() for p in project_keywords])

    return projects


def extract_entities(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏"""
    entities = []

    # –ß–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    numbers = re.findall(r'(\d+(?:\.\d+)?\s*(?:–º–ª–Ω|—Ç—ã—Å|–∫–º|—Ç–æ–Ω–Ω|—Ä—É–±–ª–µ–π|–∞–∫—Ü–∏–π|–≥–æ–¥))', text)
    entities.extend(numbers)

    # –î–∞—Ç—ã
    dates = re.findall(r'(\d{1,2}\.\d{2}\.\d{4}|\d{4}\s*–≥–æ–¥)', text)
    entities.extend(dates)

    # –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
    orgs = re.findall(r'([–ê-–Ø][–∞-—è]+\s+[–ê-–Ø][–∞-—è]+\s+(?:–∫–æ–º–ø–∞–Ω–∏—è|–æ–±—â–µ—Å—Ç–≤–æ|–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ|–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç))', text)
    entities.extend(orgs)

    return entities


if __name__ == "__main__":
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º chunks
        with open("data/processed/document_chunks.json", "r", encoding="utf-8") as f:
            chunks = json.load(f)

        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(chunks)} chunks")

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ QA –ø–∞—Ä—ã
        print("–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö QA –ø–∞—Ä...")
        qa_pairs = create_final_qa_pairs(chunks)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        with open("data/processed/qa_benchmark_final.json", "w", encoding="utf-8") as f:
            json.dump(qa_pairs, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(qa_pairs)} —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö QA –ø–∞—Ä")
        print("‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ data/processed/qa_benchmark_final.json")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –≤–æ–ø—Ä–æ—Å–æ–≤
        content_types = {}
        for pair in qa_pairs:
            content_type = pair['content_type']
            content_types[content_type] = content_types.get(content_type, 0) + 1

        print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–∏–ø–∞–º:")
        for content_type, count in content_types.items():
            print(f"  - {content_type}: {count}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        print("\nüîç –ü—Ä–∏–º–µ—Ä—ã —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö QA –ø–∞—Ä:")
        for i, pair in enumerate(qa_pairs[:5]):
            print(f"\n--- –ü—Ä–∏–º–µ—Ä {i + 1} ({pair['content_type']}) ---")
            print(f"–í–æ–ø—Ä–æ—Å: {pair['question']}")
            print(f"–†–∞–∑–¥–µ–ª—ã: {pair['sections']}")

    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª —Å chunks –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ doc_parser.py")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")