"""
ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¢Ñ€Ð°Ð½ÑÐ½ÐµÑ„Ñ‚ÑŒ QA
ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸, Ð¿ÑƒÑ‚ÐµÐ¹ Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
"""

import os
from typing import Dict, Any, List

class TransneftConfig:
    """ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ ÐºÐ»Ð°ÑÑ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¢Ñ€Ð°Ð½ÑÐ½ÐµÑ„Ñ‚ÑŒ"""
    
    # ==================== ÐŸÐ£Ð¢Ð˜ Ðš Ð”ÐÐÐÐ«Ðœ ====================
    BENCHMARK_PATH = "data/full_benchmark/transneft_benchmark.json"
    VECTOR_STORE_PATH = "vector_stores/transneft_faiss"
    RESULTS_PATH = "results"
    MODEL_CACHE_DIR = "models"
    
    # ==================== ÐœÐžÐ”Ð•Ð›Ð˜ Ð­ÐœÐ‘Ð•Ð”Ð”Ð˜ÐÐ“ÐžÐ’ ====================
    EMBEDDING_MODELS = {
        "default": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "large": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        "russian_optimized": "sentence-transformers/distiluse-base-multilingual-cased-v2"
    }
    
    # ==================== ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜ ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ˜ Ð¢Ð•ÐšÐ¡Ð¢Ð ====================
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200
    MIN_CHUNK_LENGTH = 50
    MAX_CHUNK_LENGTH = 2000
    
    # ==================== ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜ ÐŸÐžÐ˜Ð¡ÐšÐ ====================
    DEFAULT_SEARCH_K = 5
    SEARCH_CONFIGS = {
        "precision": {
            "search_type": "mmr", 
            "k": 3, 
            "fetch_k": 10,
            "lambda_mult": 0.8
        },
        "recall": {
            "search_type": "similarity", 
            "k": 7, 
            "score_threshold": 0.7
        },
        "balanced": {
            "search_type": "mmr", 
            "k": 5, 
            "fetch_k": 15, 
            "lambda_mult": 0.6
        }
    }
    
    # ==================== ÐŸÐ ÐžÐœÐ¢-Ð¨ÐÐ‘Ð›ÐžÐÐ« ====================
    PROMPT_TEMPLATES = {
        "expert": """
Ð¢Ñ‹ - ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð¿Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼ ÐŸÐÐž "Ð¢Ñ€Ð°Ð½ÑÐ½ÐµÑ„Ñ‚ÑŒ". 
ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¢ÐžÐ§ÐÐž Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°.

ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢:
{context}

Ð’ÐžÐŸÐ ÐžÐ¡: {question}

Ð¢Ð Ð•Ð‘ÐžÐ’ÐÐÐ˜Ð¯ Ðš ÐžÐ¢Ð’Ð•Ð¢Ð£:
1. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
2. Ð‘ÑƒÐ´ÑŒ Ñ‚Ð¾Ñ‡ÐµÐ½ Ð² Ñ†Ð¸Ñ„Ñ€Ð°Ñ…, Ð´Ð°Ñ‚Ð°Ñ…, Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑÑ…
3. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐ¹ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð´ÐµÐ»Ð¾Ð²Ð¾Ð¹ ÑÑ‚Ð¸Ð»ÑŒ
4. Ð•ÑÐ»Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÑ‚ - ÑÐ¾Ð¾Ð±Ñ‰Ð¸ Ð¾Ð± ÑÑ‚Ð¾Ð¼ ÑÐ²Ð½Ð¾
5. Ð”Ð»Ñ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð±ÑƒÐ´ÑŒ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ Ð²Ð½Ð¸Ð¼Ð°Ñ‚ÐµÐ»ÐµÐ½

ÐžÐ¢Ð’Ð•Ð¢:""",
        
        "detailed": """
Ð¢Ñ‹ - ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð¿Ð¾ ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ ÐŸÐÐž "Ð¢Ñ€Ð°Ð½ÑÐ½ÐµÑ„Ñ‚ÑŒ".
Ð”Ð°Ð¹ Ñ€Ð°Ð·Ð²ÐµÑ€Ð½ÑƒÑ‚Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ.

Ð”ÐÐÐÐ«Ð•:
{context}

Ð—ÐÐŸÐ ÐžÐ¡: {question}

Ð¡Ð¤ÐžÐ ÐœÐ˜Ð Ð£Ð™ ÐžÐ¢Ð’Ð•Ð¢, ÐšÐžÐ¢ÐžÐ Ð«Ð™:
- Ð¢Ð¾Ñ‡Ð½Ð¾ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ
- Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð²ÑÐµ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ñ‹
- Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð¸ Ð¿Ð¾Ð½ÑÑ‚ÐµÐ½
- ÐÐµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð²Ñ‹Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸

ÐŸÐ ÐžÐ¤Ð•Ð¡Ð¡Ð˜ÐžÐÐÐ›Ð¬ÐÐ«Ð™ ÐžÐ¢Ð’Ð•Ð¢:""",
        
        "concise": """
ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: {context}

Ð’Ð¾Ð¿Ñ€Ð¾Ñ: {question}

ÐšÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°:"""
    }
    
    # ==================== ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜ ÐœÐžÐ”Ð•Ð›Ð•Ð™ ====================
    MODEL_CONFIGS = {
        "openai": {
            "model_name": "gpt-3.5-turbo",
            "temperature": 0.1,
            "max_tokens": 1000,
            "timeout": 30
        },
        "local": {
            "model_name": "local/fallback",
            "temperature": 0.1,
            "max_tokens": 500
        }
    }
    
    # ==================== ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ ÐžÐ¦Ð•ÐÐšÐ˜ ====================
    METRICS_CONFIG = {
        "rouge_types": ['rouge1', 'rouge2', 'rougeL'],
        "bleu_weights": [(1.0,), (0.5, 0.5), (0.33, 0.33, 0.34)],
        "bertscore_lang": "ru",
        "evaluation_sample_sizes": [10, 30, 50, 100],
        "score_thresholds": {
            "excellent": 0.8,
            "good": 0.6,
            "acceptable": 0.4,
            "poor": 0.2
        }
    }
    
    # ==================== ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜ Ð˜ÐÐ¢Ð•Ð Ð¤Ð•Ð™Ð¡Ð ====================
    UI_CONFIG = {
        "page_title": "ðŸ¤– Ð¢Ñ€Ð°Ð½ÑÐ½ÐµÑ„Ñ‚ÑŒ QA Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð°",
        "page_icon": "ðŸ›¢ï¸",
        "layout": "wide",
        "initial_sidebar_state": "expanded",
        "max_chat_history": 50,
        "default_theme": "light"
    }


def get_model_config(mode: str = "balanced") -> Dict[str, Any]:
    """
    ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ð¾ Ñ€ÐµÐ¶Ð¸Ð¼Ñƒ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
    
    Args:
        mode: Ð ÐµÐ¶Ð¸Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ ("precision", "recall", "balanced")
    
    Returns:
        Dict Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼Ð¸ Ð¿Ð¾Ð¸ÑÐºÐ°
    """
    return TransneftConfig.SEARCH_CONFIGS.get(
        mode, 
        TransneftConfig.SEARCH_CONFIGS["balanced"]
    )


def validate_benchmark_path() -> bool:
    """
    ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð° Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°
    
    Returns:
        bool: True ÐµÑÐ»Ð¸ Ñ„Ð°Ð¹Ð» ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
    """
    return os.path.exists(TransneftConfig.BENCHMARK_PATH)


def get_embedding_model_config(model_size: str = "default") -> Dict[str, Any]:
    """
    ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²
    
    Args:
        model_size: Ð Ð°Ð·Ð¼ÐµÑ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ("default", "large", "russian_optimized")
    
    Returns:
        Dict Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    """
    model_name = TransneftConfig.EMBEDDING_MODELS.get(
        model_size, 
        TransneftConfig.EMBEDDING_MODELS["default"]
    )
    
    return {
        "model_name": model_name,
        "model_kwargs": {'device': 'cpu'},
        "encode_kwargs": {'normalize_embeddings': True}
    }


def get_prompt_template(template_type: str = "expert") -> str:
    """
    ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð¿Ñ€Ð¾Ð¼Ñ‚Ð° Ð¿Ð¾ Ñ‚Ð¸Ð¿Ñƒ
    
    Args:
        template_type: Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð¼Ñ‚Ð° ("expert", "detailed", "concise")
    
    Returns:
        str: Ð¢ÐµÐºÑÑ‚ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°
    """
    return TransneftConfig.PROMPT_TEMPLATES.get(
        template_type,
        TransneftConfig.PROMPT_TEMPLATES["expert"]
    )


def setup_directories() -> None:
    """
    Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
    """
    directories = [
        TransneftConfig.RESULTS_PATH,
        TransneftConfig.VECTOR_STORE_PATH,
        TransneftConfig.MODEL_CACHE_DIR,
        "data",
        "logs"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)


class EvaluationCriteria:
    """ÐšÑ€Ð¸Ñ‚ÐµÑ€Ð¸Ð¸ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
    
    @staticmethod
    def get_quality_level(score: float, metric: str) -> str:
        """
        ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¿Ð¾ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐµ
        
        Args:
            score: Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
            metric: ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        
        Returns:
            str: Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°
        """
        thresholds = TransneftConfig.METRICS_CONFIG["score_thresholds"]
        
        if score >= thresholds["excellent"]:
            return "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾"
        elif score >= thresholds["good"]:
            return "Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾"
        elif score >= thresholds["acceptable"]:
            return "Ð£Ð´Ð¾Ð²Ð»ÐµÑ‚Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾"
        else:
            return "Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ"
    
    @staticmethod
    def calculate_overall_score(metrics: Dict[str, float]) -> float:
        """
        Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð±Ð°Ð»Ð» ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
        
        Args:
            metrics: Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸
        
        Returns:
            float: ÐžÐ±Ñ‰Ð¸Ð¹ Ð±Ð°Ð»Ð» (0-1)
        """
        # Ð’ÐµÑÐ° Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        weights = {
            'rouge1': 0.25,
            'rouge2': 0.20,
            'rougeL': 0.20,
            'bleu': 0.15,
            'bertscore': 0.20
        }
        
        total_score = 0.0
        total_weight = 0.0
        
        for metric, weight in weights.items():
            if metric in metrics:
                total_score += metrics[metric] * weight
                total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0.0