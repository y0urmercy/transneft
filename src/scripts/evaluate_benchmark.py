import os
import sys
import json
from typing import List, Dict

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
current_dir = os.path.dirname(os.path.abspath(__file__))
src_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, src_root)

from core.qa_system import TransneftQASystem
from utils.config import BENCHMARK_PATH


class BenchmarkEvaluator:
    """–û—Ü–µ–Ω–∫–∞ QA-—Å–∏—Å—Ç–µ–º—ã –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ"""

    def __init__(self):
        try:
            self.qa_system = TransneftQASystem()
            self.results = []
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ QA —Å–∏—Å—Ç–µ–º—ã: {e}")
            raise

    def evaluate_system(self, benchmark_path: str = BENCHMARK_PATH) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –Ω–∞ –≤—Å–µ–º –±–µ–Ω—á–º–∞—Ä–∫–µ"""
        print("üéØ –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê QA-–°–ò–°–¢–ï–ú–´")
        print("=" * 50)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫
        benchmark = self._load_benchmark(benchmark_path)
        if not benchmark:
            return 0.0

        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {len(benchmark)} –≤–æ–ø—Ä–æ—Å–∞—Ö...")

        correct_answers = 0

        for i, item in enumerate(benchmark):
            question = item['question']
            expected_answer = item['answer']

            print(f"   {i + 1:2d}. {question[:50]}...", end=" ")

            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç —Å–∏—Å—Ç–µ–º—ã
            system_answer = self.qa_system.answer_question(question)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
            is_correct = self._check_answer_quality(system_answer, expected_answer, question)

            if is_correct:
                correct_answers += 1
                print("‚úÖ")
            else:
                print("‚ùå")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.results.append({
                'id': item['triplet_id'],
                'question': question,
                'expected': expected_answer,
                'actual': system_answer,
                'is_correct': is_correct,
                'category': item['metadata']['content_type']
            })

        # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
        accuracy = correct_answers / len(benchmark)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._show_results(accuracy, len(benchmark), correct_answers)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._save_results()

        return accuracy

    def _load_benchmark(self, benchmark_path: str) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–µ–Ω—á–º–∞—Ä–∫"""
        try:
            with open(benchmark_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"‚ùå –ë–µ–Ω—á–º–∞—Ä–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω: {benchmark_path}")
            return []
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}")
            return []

    def _check_answer_quality(self, system_answer: str, expected_answer: str, question: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞"""
        system_lower = system_answer.lower()
        expected_lower = expected_answer.lower()
        question_lower = question.lower()

        # –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        key_facts = {
            '–∞–∫—Ü–∏': ['724 934 300'],
            '–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞': ['26.08.1993', '1993'],
            '–∞—É–¥–∏—Ç–æ—Ä': ['–∫—ç–ø—Ç'],
            '–¥–µ—Ä–∂–∞—Ç–µ–ª—å —Ä–µ–µ—Å—Ç—Ä–∞': ['–Ω—Ä–∫', '—Ä.–æ.—Å.—Ç.'],
            '–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏': ['—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞', '–Ω–µ—Ñ—Ç–∏', '—Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥'],
            '–ø—Ä–æ—Ç—è–∂–µ–Ω–Ω–æ—Å—Ç—å': ['67 000', '67000']
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–æ–ø—Ä–æ—Å–∞
        for key, facts in key_facts.items():
            if key in question_lower:
                for fact in facts:
                    if fact in expected_lower and fact not in system_lower:
                        return False
                return True

        # –û–±—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—É—é —á–∞—Å—Ç—å –æ–∂–∏–¥–∞–µ–º–æ–≥–æ
        common_words = set(system_lower.split()) & set(expected_lower.split())
        return len(common_words) >= min(2, len(expected_lower.split()) // 2)

    def _show_results(self, accuracy: float, total: int, correct: int):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏"""
        print(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¶–ï–ù–ö–ò:")
        print(f"   üìä –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {total}")
        print(f"   ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {correct}")
        print(f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1%}")

        # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        self._analyze_by_category()

        print("\n" + "=" * 50)
        if accuracy >= 0.9:
            print("üéâ –û–¢–õ–ò–ß–ù–û–ï –ö–ê–ß–ï–°–¢–í–û! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª –æ–±–µ—Å–ø–µ—á–µ–Ω!")
        elif accuracy >= 0.8:
            print("‚úÖ –í–´–°–û–ö–û–ï –ö–ê–ß–ï–°–¢–í–û! –•–æ—Ä–æ—à–∏–µ —à–∞–Ω—Å—ã –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª!")
        elif accuracy >= 0.7:
            print("‚ö†Ô∏è  –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û")
        else:
            print("‚ùå –¢–†–ï–ë–£–ï–¢–°–Ø –î–û–†–ê–ë–û–¢–ö–ê")

    def _analyze_by_category(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        from collections import defaultdict
        category_stats = defaultdict(lambda: {'total': 0, 'correct': 0})

        for result in self.results:
            category = result['category']
            category_stats[category]['total'] += 1
            if result['is_correct']:
                category_stats[category]['correct'] += 1

        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        for category, stats in sorted(category_stats.items()):
            accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
            print(f"   {category}: {stats['correct']}/{stats['total']} ({accuracy:.1%})")

    def _save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        try:
            results_dir = os.path.join(src_root, "evaluation")
            os.makedirs(results_dir, exist_ok=True)

            results_path = os.path.join(results_dir, "benchmark_evaluation_results.json")
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)

            print(f"üíæ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")


def main():
    """–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        evaluator = BenchmarkEvaluator()
        accuracy = evaluator.evaluate_system()

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞ –¥–ª—è CI/CD
        sys.exit(0 if accuracy >= 0.7 else 1)

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()