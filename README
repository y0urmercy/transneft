# 🎯 Кейс 3: AI Чат-бот для ПАО «Транснефть»

## 📋 Оглавление
- [Описание проекта](#описание-проекта)
- [Стек технологий](#стек-технологий)
- [Архитектура системы](#архитектура-системы)
- [Процесс обработки данных](#процесс-обработки-данных)
- [Установка и запуск](#установка-и-запуск)
- [Проверка метрик качества](#проверка-метрик-качества)
- [Бенчмарк](#бенчмарк)
- [Демонстрация работы](#демонстрация-работы)
- [Результаты оценки](#результаты-оценки)

## 🚀 Описание проекта

**Цель**: Разработать AI систему вопросов и ответов (QA) с автоматизированным механизмом обработки запросов на основе базы знаний ПАО «Транснефть».

**Основные характеристики**:
- 📊 **Точность**: 97.5% на 40 QA-триплетах
- ⚡ **Скорость**: < 0.01 сек на вопрос
- 🔍 **Подход**: Retrieval-based (семантический поиск)
- 🎯 **Метрики**: NDCG@10=0.94, MRR@10=1.00, MAP@100=0.95

## 💻 Стек технологий

### Ядро системы
- **Python 3.9+** - основной язык программирования
- **PyTorch 2.0+** - фреймворк глубокого обучения
- **Sentence Transformers** - многозадачные модели для эмбеддингов
- **FAISS (Facebook AI Similarity Search)** - высокопроизводительный векторный поиск
- **NumPy & SciPy** - научные вычисления и линейная алгебра

### Обработка естественного языка
- **NLTK** - токенизация, стемминг, обработка текста
- **Scikit-learn** - машинное обучение и метрики оценки
- **python-docx** - парсинг документов формата .docx

### Метрики и оценка качества
- **BLEURT** - Bilingual Evaluation Understudy with Representations from Transformers
- **ROUGE** - Recall-Oriented Understudy for Gisting Evaluation
- **Semantic Similarity** - косинусное сходство эмбеддингов
- **NDCG/MRR/MAP** - метрики ранжирования и поиска

### Вспомогательные библиотеки
- **tqdm** - индикаторы прогресса
- **pandas** - обработка структурированных данных
- **regex** - расширенные регулярные выражения

## 🏗️ Архитектура системы

### Многоуровневая архитектура
┌─────────────────┐ ┌──────────────────┐ ┌──────────────────┐
│ Исходный │ -> │ Парсинг и │ -> │ Семантическое │
│ документ │ │ структурирование│ │ чанкование │
│ (.docx) │ │ │ │ │
└─────────────────┘ └──────────────────┘ └──────────────────┘
│
┌─────────────────┐ ┌──────────────────┐ ▼
│ Пользователь │ -> │ QA System │ ┌──────────────────┐
│ (вопрос) │ │ Engine │ │ Векторное │
└─────────────────┘ └──────────────────┘ │ хранилище │
│ │ │ (FAISS) │
▼ ▼ └──────────────────┘
┌─────────────────┐ ┌──────────────────┐ │
│ Ответ │ <- │ Retrieval │ ←───────────┘
│ системы │ │ Engine │
└─────────────────┘ └──────────────────┘


### Ключевые компоненты

1. **Document Parser** - извлечение структуры из .docx
2. **Semantic Chunker** - интеллектуальное разделение на смысловые блоки
3. **Vector Store** - создание и управление векторными эмбеддингами
4. **Retrieval Engine** - семантический поиск релевантных фрагментов
5. **Answer Extractor** - точное извлечение ответов из контекста

## 🔄 Процесс обработки данных

### Этап 1: Парсинг документа

```python
# Используется python-docx для извлечения структуры
document = DocumentParser().parse_document("transneft.docx")

# Результат:
# - 356 структурных элементов
# - 70 разделов документа
# - Разбивка по типам: параграфы, заголовки, списки

### Этап 2: Семантическое чанкование

# Интеллектуальное разделение на смысловые блоки
chunker = SemanticChunker()
chunks = chunker.create_chunks(document_elements)

# Алгоритм:
# 1. Анализ семантической связности
# 2. Сохранение контекстной целостности  
# 3. Оптимизация размера для поиска
# Результат: 65 семантических chunks


###Этап 3: Векторизация и индексация
# Используется модель sentence-transformers
model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

# Параметры модели:
# - 768-мерные эмбеддинги
# - Поддержка русского языка
# - Косинусная схожесть

# Создание FAISS индекса
vector_store = VectorStore()
vector_store.create_embeddings(chunks)

###Этап 4: Семантический поиск

# Поиск релевантных фрагментов
results = vector_store.search(question, k=5)

# Процесс:
# 1. Эмбеддинг вопроса
# 2. Поиск ближайших соседей в векторном пространстве
# 3. Ранжирование по косинусной схожести


###Этап 5: Извлечение ответа

# Точное извлечение ответа из контекста
engine = RetrievalEngine()
answer = engine.answer_question(question, contexts)

# Стратегии:
# - Поиск точных фактов (даты, числа, имена)
# - Извлечение структурированной информации
# - Выбор наиболее релевантного контекста
